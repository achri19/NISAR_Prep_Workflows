{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6195696-d4f9-425c-b7a9-79c7aac18903",
   "metadata": {},
   "source": [
    "# <img src=\"https://upload.wikimedia.org/wikipedia/commons/6/60/NISAR_artist_concept.jpg\" width=400 align=\"left\"/>\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/9/9b/NISAR_Mission_Logo.png\" width=400 align=\"left\"/><br><br><br><br><br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7ba3b7-d7e0-4f8d-be90-f4fea8db69c0",
   "metadata": {},
   "source": [
    "# Convert ALOS2 Data to GCOV\n",
    "\n",
    "In preparation for NISAR, this notebook converts ALOS-2 SLC data to NISAR RSLC to NISAR GCOV.\n",
    "\n",
    "\n",
    "These steps can be run in the command line, details are below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a41cd0-91b7-4afe-88ad-dbce4b3e941a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "import fnmatch\n",
    "import zipfile\n",
    "import h5py\n",
    "from string import Template\n",
    "from osgeo import gdal\n",
    "import numpy as np\n",
    "import math\n",
    "import boto3\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15590b4e-2359-4f57-9953-6b2c7aef75b5",
   "metadata": {},
   "source": [
    "## Choose your place to save your outputs. \n",
    "\n",
    "The home directory should be used (not scratch) unless very large storage space is needed. Files will be moved to the S3 bucket after processing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b3d3d1-4f46-403c-b680-628cfcb7c682",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "notebook_dir = Path(os.getcwd())\n",
    "working_dir = Path('/scratch/alex_eco_test/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45735e93-ba3c-4d39-a946-8d56256ec4d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bucket_name = \"nisar-st-data-ondemand\"\n",
    "# s3_path = 'alex/ALOS2_zip/'\n",
    "s3_path = 'ALOS2_zip/'\n",
    "s3 = boto3.client(\"s3\")\n",
    "response = s3.list_objects_v2(\n",
    "            Bucket=bucket_name,\n",
    "            Prefix = s3_path)\n",
    "            # MaxKeys=100)\n",
    "            # Delimiter = '/')\n",
    "contents = response.get('Contents')\n",
    "existing_ALOS2_zipfiles = [contents[i].get('Key').split('/')[-1] for i in range(len(contents)) if '.zip' in contents[i].get('Key')]\n",
    "existing_ALOS2_zippaths = [contents[i].get('Key') for i in range(len(contents)) if '.zip' in contents[i].get('Key')]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3525da-c42f-4fab-9f71-6654b05bd3bf",
   "metadata": {},
   "source": [
    "## Choose your AOI\n",
    "\n",
    "New directories will be made to store files for this AOI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602162d6-d82a-4ff8-a14b-923cfa434733",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "aoi = 'TALL'\n",
    "aoi_str = aoi.replace(\" \", \"_\")\n",
    "\n",
    "\n",
    "aoi_dir = working_dir/aoi_str\n",
    "RSLC_dir = aoi_dir / 'RSLC'\n",
    "ALOS2_dir = aoi_dir / 'ALOS2'\n",
    "DEM_dir = aoi_dir / 'DEM'\n",
    "GCOV_dir = aoi_dir / 'GCOV'\n",
    "TMP_dir = aoi_dir / 'TMP'\n",
    "\n",
    "Path(aoi_dir).mkdir(parents=True, exist_ok=True)\n",
    "Path(RSLC_dir).mkdir(parents=True, exist_ok=True)\n",
    "Path(ALOS2_dir).mkdir(parents=True, exist_ok=True)\n",
    "Path(DEM_dir).mkdir(parents=True, exist_ok=True)\n",
    "Path(GCOV_dir).mkdir(parents=True, exist_ok=True)\n",
    "Path(TMP_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e80d13b-1dc0-4c12-8ec5-46e8c4ef43fd",
   "metadata": {},
   "source": [
    "## Get the ALOS2 URLs "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292c6f64-4067-4c62-a2c6-99de0a0926ed",
   "metadata": {},
   "source": [
    "If you install **pandas** and **openpyxl** to your isce3_src package, you can search the ALOS2 spreadsheed directly. Otherwise, you need to copy the list of URLS manually\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a887698e-da4b-40a9-8539-78f6e1e4330c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "xlsx = pd.ExcelFile('/scratch/alex_eco_test/ALOS-2_Restricted_Available_at_ASF_20231227.xlsx')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaff9f9a-6568-42f3-9b76-19c649e93b66",
   "metadata": {},
   "source": [
    "Filter the ALOS2 data using name, path, frame, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3069c64-a7f5-4152-a8c3-a3c2c135e307",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df_filtered = df[(df['Frame']==580) & (df['Path']==51)]\n",
    "sheet = 'Forest (L1.1)'\n",
    "df = pd.read_excel(xlsx,sheet)\n",
    "df_filtered = df[df['Request']==aoi]\n",
    "list_of_ALOS_SLCs = list(df_filtered['Zip Link'])\n",
    "list_of_ALOS_SLCs.sort()\n",
    "list_of_ALOS_SLCs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142cc559-362c-4534-8499-f7cfd24c8d36",
   "metadata": {},
   "source": [
    "Or manually enter the list of URLs to download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94318727-f096-40f3-a19a-4e30e20c3335",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ## Example using Wax Lake Delta\n",
    "# list_of_ALOS_SLCs = [\n",
    "#                     'https://cumulus.asf.alaska.edu/L1.1/A4/0000436588_001001_ALOS2390510580-210816.zip',\n",
    "#                     'https://cumulus.asf.alaska.edu/L1.1/A4/0000470239_001001_ALOS2427770580-220425.zip',\n",
    "#                     'https://cumulus.asf.alaska.edu/L1.1/A4/0000475404_001001_ALOS2442260580-220801.zip',\n",
    "#                     'https://cumulus.asf.alaska.edu/L1.1/A4/0000477810_001001_ALOS2444330580-220815.zip',\n",
    "#                     'https://cumulus.asf.alaska.edu/L1.1/A4/0000479846_001001_ALOS2446400580-220829.zip',\n",
    "#                     'https://cumulus.asf.alaska.edu/L1.1/A4/0000509061_001001_ALOS2479520580-230410.zip',\n",
    "#                     'https://cumulus.asf.alaska.edu/L1.1/A4/0000510737_001001_ALOS2481590580-230424.zip',\n",
    "#                     'https://cumulus.asf.alaska.edu/L1.1/A4/0000526924_001001_ALOS2498150580-230814.zip',\n",
    "#                     'https://cumulus.asf.alaska.edu/L1.1/A4/0000528515_001001_ALOS2500220580-230828.zip',\n",
    "                    \n",
    "#                     ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32a3160-3d4b-424d-be88-5ad1a0a28b58",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Download the ALOS2 files using wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8af914-2a30-4b67-902d-cca76564430a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ALOS2_ids = []\n",
    "response = s3.list_objects_v2(\n",
    "            Bucket=bucket_name,\n",
    "            Prefix = s3_path)\n",
    "            # MaxKeys=100)\n",
    "            # Delimiter = '/')\n",
    "contents = response.get('Contents')\n",
    "existing_ALOS2_zipfiles = [contents[i].get('Key').split('/')[-1] for i in range(len(contents)) if '.zip' in contents[i].get('Key')]\n",
    "existing_ALOS2_zippaths = [contents[i].get('Key') for i in range(len(contents)) if '.zip' in contents[i].get('Key')]\n",
    "\n",
    "for file in list_of_ALOS_SLCs[:]:\n",
    "    filename =  file.split('/')[-1]\n",
    "    ALOS2_ids.append(filename)\n",
    "    print('Requested File: ', filename)\n",
    "    print(os.path.isdir(ALOS2_dir/filename.split('/')[-1][:-4]))\n",
    "    print(os.path.isfile(ALOS2_dir/filename))\n",
    "    print((filename in existing_ALOS2_zipfiles))\n",
    "    if os.path.isdir(ALOS2_dir/filename.split('/')[-1][:-4])==True & (filename in existing_ALOS2_zipfiles)==True:\n",
    "        print('ALOS2 is stored on S3 and already available locally and unzipped')\n",
    "    elif (os.path.isfile(ALOS2_dir/filename)==False) & (filename in existing_ALOS2_zipfiles):\n",
    "        i = existing_ALOS2_zipfiles.index(filename)\n",
    "        s3_path_new = existing_ALOS2_zippaths[i]\n",
    "        print('\\tALOS2 zip is already available at S3 PATH: ', s3_path_new)\n",
    "        s3.download_file(bucket_name, s3_path_new , filename)\n",
    "        print('\\tMove ALOS2 zip from S3 to local')\n",
    "        shutil.move(notebook_dir/filename, ALOS2_dir/filename)\n",
    "        \n",
    "    elif (os.path.isfile(ALOS2_dir/filename)==False) & (filename not in existing_ALOS2_zipfiles):\n",
    "        print('\\tALOS2 is not available anywhere')\n",
    "        print('\\tDownloading ALOS2 zip ')\n",
    "        command = f\"wget -P {ALOS2_dir} -q {file}\"\n",
    "        output = subprocess.check_output(command, shell=True)\n",
    "        print('\\tMoving a copy ALOS2 zip to S3 bucket')\n",
    "        s3.upload_file(Filename= str(ALOS2_dir / filename), Bucket=bucket_name, Key='%s%s/%s' %(s3_path,aoi_str,filename))\n",
    "    \n",
    "    elif (os.path.isfile(ALOS2_dir/filename)==True) & (filename not in existing_ALOS2_zipfiles):\n",
    "        print('\\tALOS2 is available locally, but not on S3')\n",
    "        print('\\tMoving a copy ALOS2 zip to S3 bucket')\n",
    "        s3.upload_file(Filename= str(ALOS2_dir / filename), Bucket=bucket_name, Key='%s%s/%s' %(s3_path,aoi_str,filename))\n",
    "\n",
    "    else: \n",
    "        print('\\tALOS2 zip file exists locally and on S3')\n",
    "        \n",
    "    if os.path.isdir(ALOS2_dir/filename.split('/')[-1][:-4])==False:\n",
    "        print('\\tunzipping the ALOS2 file locally')\n",
    "        try:\n",
    "            with zipfile.ZipFile(ALOS2_dir/filename, 'r') as zip_ref:\n",
    "                zip_ref.extractall(ALOS2_dir/filename.split('/')[-1][:-4])\n",
    "        except:\n",
    "            print('\\tALOS2 zip is bad, re-downloading')\n",
    "            os.remove(ALOS2_dir/filename)\n",
    "            command = f\"wget -P {ALOS2_dir} -q {file}\"\n",
    "            output = subprocess.check_output(command, shell=True)\n",
    "            print('\\t\\tMoving a copy ALOS2 zip to S3 bucket')\n",
    "            s3.upload_file(Filename= str(ALOS2_dir / filename), Bucket=bucket_name, Key='%s%s/%s' %(s3_path,aoi_str,filename))\n",
    "            with zipfile.ZipFile(ALOS2_dir/filename, 'r') as zip_ref:\n",
    "                zip_ref.extractall(ALOS2_dir/filename.split('/')[-1][:-4])\n",
    "        print('\\t\\tdeleting the local zip file')\n",
    "        # os.remove(ALOS2_dir/filename) ## comment to remove the alos2 zip file from your local workspace\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af65b7df-5d79-42a9-b287-4002d325c12b",
   "metadata": {},
   "source": [
    "## Get a list of folders for each ALOS2 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23858301-de8e-430d-9ea1-e035e702f86d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ALOS2folders = [os.path.join(dirpath,f)\n",
    "                for dirpath,dirnames, files in os.walk(ALOS2_dir)\n",
    "                for f in fnmatch.filter(dirnames,'*')]\n",
    "ALOS2folders.sort()\n",
    "ALOS2folders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483fe034-9202-4f1f-b98a-a4d7be286570",
   "metadata": {},
   "source": [
    "## Convert ALOS2 SLC to NISAR RSLC format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7547e9d0-23a1-464e-b920-75670ab3a6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ALOS2folder in ALOS2folders[:]:\n",
    "    ALOS2_id = ALOS2folder.split('/')[-1]\n",
    "    print('')\n",
    "    print(ALOS2_id)\n",
    "    \n",
    "    ##ALOS2 SLC --> NISAR RSLC\n",
    "    command = f\"conda run -n isce3_src /home/jovyan/isce3/share/nisar/examples/alos2_to_nisar_l1.py -i {ALOS2folder} -o {RSLC_dir/ALOS2_id}.h5\"\n",
    "  \n",
    "    if os.path.isfile(f\"{RSLC_dir/ALOS2_id}.h5\")==True:\n",
    "        print('NISAR RSLC already converted')\n",
    "    else:\n",
    "            \n",
    "        try: os.remove(f\"{RSLC_dir/ALOS2_id}.h5\")\n",
    "        except:''\n",
    "        output = subprocess.check_output(command, shell=True)    \n",
    "        print('')\n",
    "        print(command)  \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae06bbb-0002-497b-ac2d-6bb90f8b412d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ALOS2_RSLCs = [os.path.join(dirpath,f)\n",
    "                for dirpath,dirnames, files in os.walk(RSLC_dir)\n",
    "                for f in fnmatch.filter(files,'*')]\n",
    "ALOS2_RSLCs.sort()\n",
    "ALOS2_RSLCs\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1bd920-03ba-495b-b4b2-80d3c13b3714",
   "metadata": {},
   "source": [
    "## Get a DEM for the first ALOS2 file in the stack "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082b7233-90df-483a-9832-5cd8754e6104",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "ALOS2_ref = ALOS2_RSLCs[0].split('/')[-1][:-3]\n",
    "print('')\n",
    "print(ALOS2_ref)\n",
    "\n",
    "## Get NISAR DEM\n",
    "command = f\"conda run -n isce3_src /home/jovyan/isce3/python/packages/nisar/workflows/stage_dem.py -p {RSLC_dir/ALOS2_ref}.h5 -o {DEM_dir/ALOS2_ref}.vrt\"\n",
    "   \n",
    "\n",
    "if os.path.isfile(f\"{DEM_dir/ALOS2_ref}.vrt\")==False:\n",
    "    print('')\n",
    "    print(command) \n",
    "    output = subprocess.check_output(command, shell=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d98b8a4-6741-46dc-9cd4-2d56167cbbd0",
   "metadata": {},
   "source": [
    "## Process NISAR RSLC to GCOV\n",
    "\n",
    "### If you want to change to UTM coordiates, set utm = True and choose the x and y posting. The default is 20m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae768f9-8dd0-4920-8be9-272f5117f439",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_posting = ''\n",
    "y_posting = ''\n",
    "EPSG = ''\n",
    "\n",
    "utm = True\n",
    "if utm:\n",
    "    src = gdal.Open(f\"{DEM_dir/ALOS2_ref}.vrt\")\n",
    "    ulx, xres, xskew, uly, yskew, yres  = src.GetGeoTransform()\n",
    "    lrx = ulx + (src.RasterXSize * xres)\n",
    "    lry = uly + (src.RasterYSize * yres)\n",
    "\n",
    "    x1,y1,x2,y2 = math.floor(ulx),math.floor(uly),math.floor(lrx),math.floor(lry)\n",
    "    zone = int(np.ceil((ulx + 180)/6))\n",
    "\n",
    "    if y1>=0:\n",
    "        EPSG = 32600+zone\n",
    "    elif y1<0:\n",
    "        EPSG = 32600+zone\n",
    "\n",
    "    x_posting = 20\n",
    "    y_posting = 20\n",
    "    \n",
    "print(EPSG)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4481a71c-33d7-4246-a7d7-27b30aac5163",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Run the GCOV processor on the first/reference image in the stack. \n",
    "This image will be used to determine the bounding box of the remaining images in the stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17981e8e-acce-4827-8362-e7df9ebd49f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filein = open('gcov_template.yaml')\n",
    "template = Template(filein.read())\n",
    "replacements = {'inputfile':  f\"{RSLC_dir/ALOS2_ref}.h5\",\n",
    "                'outputfile':  f\"{GCOV_dir/ALOS2_ref}_gcov_%s.h5\" %(EPSG),\n",
    "                'demfile': f\"{DEM_dir/ALOS2_ref}.vrt\",\n",
    "                'tmp': f\"{TMP_dir}/\",\n",
    "                'epsg': EPSG,\n",
    "                'xposting': x_posting,\n",
    "                'yposting': y_posting,\n",
    "                'top_left_y': '',\n",
    "                'top_left_x' : '',\n",
    "                'bottom_right_y':'',\n",
    "                'bottom_right_x':'',\n",
    "                'y_snap':'',\n",
    "                'x_snap':''\n",
    "                }\n",
    "makeoutput = template.substitute(replacements)\n",
    "file = open('%s/%s.yaml' %(GCOV_dir,ALOS2_ref),'w')\n",
    "file.write(makeoutput)\n",
    "file.close()\n",
    "filein.close()\n",
    "\n",
    "command = f\"conda run -n isce3_src /home/jovyan/isce3/python/packages/nisar/workflows/gcov.py {GCOV_dir/ALOS2_ref}.yaml\"\n",
    "\n",
    "if os.path.isfile(f\"{GCOV_dir/ALOS2_ref}_gcov_utm.h5\")==False:\n",
    "    print('')\n",
    "    print(command)\n",
    "    output = subprocess.check_output(command, shell=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26a7646-f1ca-468c-8c1c-f9266d5c650c",
   "metadata": {},
   "source": [
    "## Get top left coordinates of bottom right coordinates of reference image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382aa198-2fe3-4ad7-93f3-443cb0c810ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f = h5py.File(f\"{GCOV_dir/ALOS2_ref}_gcov_%s.h5\" %(EPSG), \"r\") \n",
    "a_group_key = list(f.keys())[0]\n",
    "ds_x = f[a_group_key]['LSAR']['GCOV']['grids']['frequencyA']['xCoordinates'][()]      # returns as a h5py dataset object\n",
    "ds_y = f[a_group_key]['LSAR']['GCOV']['grids']['frequencyA']['yCoordinates'][()]      # returns as a h5py dataset object\n",
    "\n",
    "ulx = x_posting * round(ds_x[0]/x_posting)\n",
    "lrx = x_posting * round(ds_x[-1]/x_posting)\n",
    "uly = y_posting * round(ds_y[0]/y_posting)\n",
    "lry = y_posting * round(ds_y[-1]/y_posting)\n",
    "\n",
    "print('Force top left to be: %s %s' %(ulx,uly))\n",
    "print('Force top right to be: %s %s' %(lrx,lry))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e7bd85-8e2e-4741-a86e-f95f29ec8202",
   "metadata": {},
   "source": [
    "## Process the remaining RSLC files to GCOV using the bounding box set by the reference images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb60850-d567-4f8e-8eaf-8106f6c7c46e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for ALOS2_RSLC in ALOS2_RSLCs[:]:\n",
    "    ALOS2_id = ALOS2_RSLC.split('/')[-1][:-3]\n",
    "    print('')\n",
    "    print(ALOS2_id)\n",
    "\n",
    "    filein = open('gcov_template.yaml')\n",
    "    template = Template(filein.read())\n",
    "    replacements = {'inputfile':  f\"{RSLC_dir/ALOS2_id}.h5\",\n",
    "                    'outputfile':  f\"{GCOV_dir/ALOS2_id}_gcov_%s.h5\" %(EPSG),\n",
    "                    'demfile': f\"{DEM_dir/ALOS2_ref}.vrt\",\n",
    "                    'tmp': f\"{TMP_dir}/\",\n",
    "                    'epsg': EPSG,\n",
    "                    'xposting': x_posting,\n",
    "                    'yposting': y_posting,\n",
    "                    'top_left_y': uly,\n",
    "                    'top_left_x':ulx,\n",
    "                    'bottom_right_y':lry,\n",
    "                    'bottom_right_x': lrx,\n",
    "                    'y_snap':'',#y_posting,\n",
    "                    'x_snap':''#x_posting\n",
    "                    }\n",
    "    makeoutput = template.substitute(replacements)\n",
    "    file = open('%s/%s.yaml' %(GCOV_dir,ALOS2_id),'w')\n",
    "    file.write(makeoutput)\n",
    "    file.close()\n",
    "    filein.close()\n",
    "\n",
    "    command = f\"conda run -n isce3_src /home/jovyan/isce3/python/packages/nisar/workflows/gcov.py {GCOV_dir/ALOS2_id}.yaml\"\n",
    "    print('')\n",
    "    print(command)\n",
    "    if os.path.isfile(f\"{GCOV_dir/ALOS2_id}_gcov_utm.h5\")==False:\n",
    "        output = subprocess.check_output(command, shell=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a797e8-7d3b-41c3-b8f7-3fe9eb3075ca",
   "metadata": {},
   "source": [
    "## See final list of NISAR GCOV data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7165d81-6957-4e14-b953-99943bda4232",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "NISAR_GCOVs = [os.path.join(dirpath,f)\n",
    "                for dirpath,dirnames, files in os.walk(GCOV_dir)\n",
    "                for f in fnmatch.filter(files,'*.h5')]\n",
    "NISAR_GCOVs.sort()\n",
    "NISAR_GCOVs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ee1c2a-43ce-4b95-9599-2e005ed67f3d",
   "metadata": {},
   "source": [
    "## Check that all H5 files have the same dimensions and extent\n",
    "## Make Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223aaeb3-5a33-47fb-9320-a73d4116beff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "for NISAR_GCOV in NISAR_GCOVs[:]:\n",
    "    ALOS2_id = NISAR_GCOV.split('/')[-1][:-3]\n",
    "    print('')\n",
    "    print(ALOS2_id)\n",
    "    f = h5py.File(f\"{GCOV_dir/ALOS2_id}.h5\", \"r\") \n",
    "    a_group_key = list(f.keys())[0]\n",
    "    ds_x = f[a_group_key]['LSAR']['GCOV']['grids']['frequencyA']['xCoordinates'][()]      # returns as a h5py dataset object\n",
    "    ds_y = f[a_group_key]['LSAR']['GCOV']['grids']['frequencyA']['yCoordinates'][()]      # returns as a h5py dataset object\n",
    "    HH = f[a_group_key]['LSAR']['GCOV']['grids']['frequencyA']['HHHH'][()] \n",
    "    HV = f[a_group_key]['LSAR']['GCOV']['grids']['frequencyA']['HVHV'][()] \n",
    "    print('Width x Height:' , ds_x.shape, ds_y.shape)\n",
    "    ulx = x_posting * round(ds_x[0]/x_posting)\n",
    "    lrx = x_posting * round(ds_x[-1]/x_posting)\n",
    "    uly = y_posting * round(ds_y[0]/y_posting)\n",
    "    lry = y_posting * round(ds_y[-1]/y_posting)\n",
    "    extent= (ulx, lry, lrx, uly) \n",
    "    print('Top Left: ', ulx,uly)\n",
    "    print('Bottom Right: ', lrx,lry)\n",
    "    \n",
    "    fig, [ax1,ax2] = plt.subplots(1,2,figsize = (15,10))\n",
    "    im1 = ax1.imshow(HH, interpolation = 'nearest',\n",
    "          extent = extent, vmin=0,vmax=0.5,cmap='viridis')\n",
    "    cbar1 = plt.colorbar(im1, ax=ax1,\n",
    "            shrink=0.5, orientation='horizontal',\n",
    "            pad=0.1, aspect=50,label='HH')\n",
    "    im2 = ax2.imshow(HV, interpolation = 'nearest',\n",
    "          extent = extent, vmin=0,vmax=0.1,cmap='viridis')\n",
    "    cbar2 = plt.colorbar(im2, ax=ax2,\n",
    "            shrink=0.5, orientation='horizontal',\n",
    "            pad=0.1, aspect=50,label='HV')\n",
    "    plt.suptitle(ALOS2_id)\n",
    "    plt.savefig(GCOV_dir/ (ALOS2_id + '_HH-HV.png'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d59df0c-a650-4d58-97c3-65f23897dcad",
   "metadata": {},
   "source": [
    "## Make an animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e82b57-c843-4a2c-824a-ec49efa886d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_figs = [os.path.join(dirpath,f)\n",
    "                for dirpath,dirnames, files in os.walk(GCOV_dir)\n",
    "                for f in fnmatch.filter(files,'*.png')]\n",
    "all_figs.sort()\n",
    "with imageio.get_writer('%s/%s.gif' %(GCOV_dir,aoi_str),mode='I',duration=300) as writer:\n",
    "    for file in all_figs:\n",
    "        print(file)\n",
    "        image = imageio.imread(file)\n",
    "        writer.append_data(image)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40bb0664-980c-420e-a4d6-b62e0082a999",
   "metadata": {},
   "source": [
    "## Clean TMP files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c108fbb-f050-4a35-9db5-d66e86cb8461",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "shutil.rmtree(TMP_dir) \n",
    "shutil.rmtree(ALOS2_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afcf3776-ae14-41bb-9f7e-f053000a393d",
   "metadata": {},
   "source": [
    "## Move files to S3 Bucket\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d408a5-554c-436a-93b3-b5c83bb717de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# folders = [os.path.join(dirpath,f)\n",
    "#                 for dirpath,dirnames, files in os.walk(aoi_dir)\n",
    "#                 for f in fnmatch.filter(dirnames,'*')]\n",
    "# for folder in folders:\n",
    "#     files = [os.path.join(dirpath,f)\n",
    "#                 for dirpath,dirnames, files in os.walk(folder)\n",
    "#                 for f in fnmatch.filter(files,'*')]\n",
    "#     # print(folder)\n",
    "#     parent = folder.split('/')[-1]\n",
    "#     print(parent)\n",
    "#     for file in files:\n",
    "#         print(file)\n",
    "#         os.system('aws s3 mv %s s3://nisar-st-data-ondemand/ALOS2_processed/%s/%s/%s' %(file,aoi_str,parent,file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4358256b-bb79-4fcc-91a7-160fda690c78",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Command line option\n",
    "\n",
    "######## ALOS2 SLC to NISAR RSLC\n",
    "# for f in /scratch/alex_eco_test/ALOS2/southfork/*/; \n",
    "# do python /home/jovyan/isce3/share/nisar/examples/alos2_to_nisar_l1.py -i $f -o \"${f%.*}\".h5; \n",
    "# done\n",
    "\n",
    "######## Get NISAR DEM\n",
    "# for f in /scratch/alex_eco_test/ALOS2/southfork/rslc/*; \n",
    "# do python /home/jovyan/isce3/python/packages/nisar/workflows/stage_dem.py -p $f -o \"${f%.*}\".vrt; \n",
    "# done\n",
    "\n",
    "######## NISAR RSLC to NISAR GCOV\n",
    "# for f in /scratch/alex_eco_test/ALOS2/southfork/rslc/*.yaml; \n",
    "# do python /home/jovyan/isce3/python/packages/nisar/workflows/gcov.py $f; \n",
    "# done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82dd33e-745b-4180-9795-6707b3ab9f32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a4d4f9-6638-4e50-9cb2-c0527bb23980",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "isce3_src",
   "language": "python",
   "name": "isce3_src"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
